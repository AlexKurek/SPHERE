{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# IRDIFS data reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducing an IRDIFS data set can be done in several ways:\n",
    "* [SPHERE.Dataset](#sphere_dataset): reduction of multiple IRDIS and IFS data sets\n",
    "* [IFS.Reduction](#ifs_reduction): reduction of a single IFS data set\n",
    "* [IRDIS.ImagingReduction](#irdis_reduction): reduction of a single IRDIS data set\n",
    "\n",
    "\n",
    "In addition, the automated reductions can be easily configured:\n",
    "* [Reduction configuration](#reduction_configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sphere_dataset\"></a>\n",
    "## Reduction with SPHERE.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest is to create a SPHERE.Dataset object that will read the data at a specified location and reduce it using the default parameters.\n",
    "\n",
    "The first step is to create a Dataset object and provide it with a path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vltpf.SPHERE as SPHERE\n",
    "\n",
    "# data path\n",
    "path = '~/data/VLTPF-test-target/'\n",
    "\n",
    "# create the dataset\n",
    "dataset = SPHERE.Dataset(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataset object automatically search the path for (in that order):\n",
    " 1. xml files that come from datasets downloaded directly from the ESO archive. These files contain the association between the science files and the raw calibration files.\n",
    " 2. FITS files\n",
    " 3. existing valid reduction paths, i.e. directories containing a \"raw\" sub-directory with FITS files\n",
    "\n",
    "For case 1 and 2, the FITS files will be automatically sorted in directories per-target (case 1) or per-subsystem (case 2).\n",
    "\n",
    "At the end, the Dataset will contain a list of valid reductions for IFS and/or IRDIS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('List of valid reductions found in path:')\n",
    "dataset.reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('IFS reductions:')\n",
    "dataset.IFS_reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('IRDIS reductions:')\n",
    "dataset.IRDIS_reductions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for each reduction can then be reduced in a single command using the default parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.full_reduction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the full documentation to better understand how to use the Dataset object and what are the limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ifs_reduction\"></a>\n",
    "## Reduction with IFS.Reduction\n",
    "\n",
    "If you have already sorted your IFS data in a directory, you can directly create an IFS.Reduction object to reduce the data. If your reduction path is `/path/to/data/`, then the raw data must be in `/path/to/data/raw/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vltpf.IFS as IFS\n",
    "\n",
    "# data path\n",
    "path = '~/data/VLTPF-test-target/IFS/'\n",
    "\n",
    "# create the reduction\n",
    "reduction = IFS.Reduction(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different levels of control for the reduction.\n",
    "\n",
    "### Single line reduction\n",
    "\n",
    "In this reduction the user has no direct control on the reduction process. In case of failure (missing files, error, etc), the reduction will have to be restarted entirely.\n",
    "\n",
    "The user can change the main reduction parameters by accessing the `reduction.config` dictionary [(see below)](#reduction_configuration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction.full_reduction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-step reduction\n",
    "\n",
    "In this reduction, the user has still no direct control on the individual steps, but (s)he can minimise the impact of any error by restarting only the main step that failed. Note that the object has a knowledge of what steps have been executed so there is no \"risk\" of running steps in the wrong order.\n",
    "\n",
    "The user can change the main reduction parameters by accessing the reduction.config dictionary [(see below)](#reduction_configuration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation\n",
    "reduction.init_reduction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# static calibrations\n",
    "reduction.create_static_calibrations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process science data\n",
    "reduction.preprocess_science()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process science data\n",
    "reduction.process_science()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean-up\n",
    "reduction.clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual reduction\n",
    "\n",
    "In this reduction, the user has complete control over the reduction steps and their parameters. Again the object has a knowledge of what steps have been executed so there is no \"risk\" of running steps in the wrong order. Available options are detailed in the full documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort files\n",
    "reduction.sort_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract frames informations\n",
    "reduction.sort_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all required calibration files are available\n",
    "reduction.check_files_association()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate darks/backgrounds\n",
    "reduction.sph_ifs_cal_dark(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate detector flats\n",
    "reduction.sph_ifs_cal_detector_flat(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate microspectra positions\n",
    "reduction.sph_ifs_cal_specpos(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate wavelength calibration\n",
    "reduction.sph_ifs_cal_wave(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate IFU flat\n",
    "reduction.sph_ifs_cal_ifu_flat(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process science frames\n",
    "reduction.sph_ifs_preprocess_science(subtract_background=True, fix_badpix=True, correct_xtalk=True,\n",
    "                                     collapse_science=True, collapse_type='mean', coadd_value=2,\n",
    "                                     collapse_psf=True, collapse_center=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process wavelength calibration file for recalibration\n",
    "reduction.sph_ifs_preprocess_wave()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate individual (x,y,lambda) cubes\n",
    "reduction.sph_ifs_science_cubes(postprocess=True, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalibrate wavelength\n",
    "reduction.sph_ifs_wavelength_recalibration(high_pass=False, offset=(0, 0), display=False, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine star center\n",
    "reduction.sph_ifs_star_center(high_pass=False, offset=(0, 0), display=False, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine data in (x,y,time,lambda) cubes\n",
    "reduction.sph_ifs_combine_data(cpix=True, psf_dim=80, science_dim=290, correct_anamorphism=True, \n",
    "                               shift_method='fft', nocenter=False, save_scaled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean-up\n",
    "reduction.sph_ifs_clean(delete_raw=False, delete_products=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"irdis_reduction\"></a>\n",
    "## Reduction with IRDIS.ImagingReduction\n",
    "\n",
    "If you have already sorted your IRDIS data in a directory, you can directly create an IRDIS.ImagingReduction object to reduce the data. If your reduction path is `/path/to/data/`, then the raw data must be in `/path/to/data/raw/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vltpf.IRDIS as IRDIS\n",
    "\n",
    "# data path\n",
    "path = '~/data/VLTPF-test-target/IRD/'\n",
    "\n",
    "# create the reduction\n",
    "reduction = IRDIS.ImagingReduction(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different levels of control for the reduction.\n",
    "\n",
    "### Single line reduction\n",
    "\n",
    "In this reduction the user has no direct control on the reduction process. In case of failure (missing files, error, etc), the reduction will have to be restarted entirely.\n",
    "\n",
    "The user can change the main reduction parameters by accessing the `reduction.config` dictionary [(see below)](#reduction_configuration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction.full_reduction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-step reduction\n",
    "\n",
    "In this reduction, the user has still no direct control on the individual steps, but (s)he can minimise the impact of any error by restarting only the main step that failed. Note that the object has a knowledge of what steps have been executed so there is no \"risk\" of running steps in the wrong order.\n",
    "\n",
    "The user can change the main reduction parameters by accessing the reduction.config dictionary [(see below)](#reduction_configuration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation\n",
    "reduction.init_reduction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# static calibrations\n",
    "reduction.create_static_calibrations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process science data\n",
    "reduction.preprocess_science()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process science data\n",
    "reduction.process_science()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean-up\n",
    "reduction.clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual reduction\n",
    "\n",
    "In this reduction, the user has complete control over the reduction steps and their parameters. Again the object has a knowledge of what steps have been executed so there is no \"risk\" of running steps in the wrong order. Available options are detailed in the full documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort files\n",
    "reduction.sort_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract frames informations\n",
    "reduction.sort_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all required calibration files are available\n",
    "reduction.check_files_association()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate darks/backgrounds\n",
    "reduction.sph_ird_cal_dark(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate detector flats\n",
    "reduction.sph_ird_cal_detector_flat(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process science frames to generate individual (x,y,lambda) cubes\n",
    "reduction.sph_ird_preprocess_science(subtract_background=True, fix_badpix=True,\n",
    "                                     collapse_science=False, collapse_type='mean', coadd_value=2,\n",
    "                                     collapse_psf=True, collapse_center=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine star center\n",
    "reduction.sph_ird_star_center(high_pass=False, offset=(0, 0), display=False, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine data in (x,y,time,lambda) cubes\n",
    "reduction.sph_ird_combine_data(cpix=True, psf_dim=100, science_dim=400, correct_anamorphism=True, \n",
    "                               shift_method='fft', nocenter=False, save_scaled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean-up\n",
    "reduction.sph_ird_clean(delete_raw=False, delete_products=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"reduction_configuration\"></a>\n",
    "## Reduction configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with the 1-line reduction or with the simplified step-by-step reduction steps, the reduction uses the default reduction parameters, which are stored in the ``config`` dictionary of each reduction object.\n",
    "\n",
    "The current configuration of a reduction can be accessed with the ``show_config()`` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction.show_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then each of the parameters can be independently modifed by hand. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction.config['preproc_collapse_science'] = True  # collapse science cubes...\n",
    "reduction.config['preproc_collapse_type'] = 'mean'   # ... using a mean\n",
    "\n",
    "reduction.config['combine_science_dim'] = 200        # save only images of size 200x200\n",
    "reduction.config['combine_shift_method'] = 'interp'  # use interpolation instead of FFT\n",
    "\n",
    "reduction.config['clean'] = True                     # make sure we clean at the end (default is no cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important note:\n",
    "\n",
    "> The ``config`` dictionary keys are identical between the ``IFS.Reduction`` and ``IRDIS.ImagingReduction`` objects, except for the ``preproc_correct_xtalk``, which is specific for the IFS because it controls the correction of the spectral crosstalk. However, the default value for this key should not be changed unless you are an expert user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new parameter can be checked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction.show_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then start the reduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction.full_reduction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
